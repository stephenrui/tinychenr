from read_data import *
from keras.layers import*
from keras.models import *
from keras import Sequential
from keras.optimizers import *
from keras.callbacks import *
import pandas as pd
from read_txt import loadtimes
from keras import backend as K

visit_size=25
n_chanels = 3
c=time.clock()
train_visit = 'data\\train\\'
test_visit = 'data\\test\\'
str1='data\\train_image\\001\*.jpg'
str2='data\\train_image\\002\*.jpg'
str3='data\\train_image\\003\*.jpg'
str4='data\\train_image\\004\*.jpg'
str5='data\\train_image\\005\*.jpg'
str6='data\\train_image\\006\*.jpg'
str7='data\\train_image\\007\*.jpg'
str8='data\\train_image\\008\*.jpg'
str9='data\\train_image\\009\*.jpg'
str_tr1='data\\test_load\\train\\1\\*.jpg'
str_tr2='data\\test_load\\train\\2\\*.jpg'
str_tr3='data\\test_load\\train\\3\\*.jpg'
str_tr4='data\\test_load\\train\\4\\*.jpg'
str_tr5='data\\test_load\\train\\5\\*.jpg'
str_tr6='data\\test_load\\train\\6\\*.jpg'
str_tr7='data\\test_load\\train\\7\\*.jpg'
str_tr8='data\\test_load\\train\\8\\*.jpg'
str_tr9='data\\test_load\\train\\9\\*.jpg'
str_te='data\\test_load\\test\\*.jpg'
trfiles=[str_tr1,str_tr2]#,str_tr3,str_tr4,str_tr5,str_tr6,str_tr7,str_tr8,str_tr9]#[str1,str2,str3,str4,str5,str6,str7,str8,str9]#
n_speces = len(trfiles)
trsample,_ = concate_data(trfiles,False)
t0 = time.clock()
str11='data\\test_image\\*.jpg'
'''str22='data\\test_image\\002\*.jpg'
str33='data\\test_image\\003\*.jpg'
str44='data\\test_image\\004\*.jpg'
str55='data\\test_image\\005\*.jpg'''
tefiles=[str_te]#[str11]
tesample,org = concate_data(tefiles,False)
'''
for i in range(len(trsample)):
    trsample[i][3] = train_visit+trsample[i][2][:10]+'.txt'
    trsample[i][3],_ = loadtimes(trsample[i][3])
    if i%100==0:
        pro = 1.0*i/len(trsample)
        a=time.asctime(time.localtime(time.time()))
        print(a,'---------Reading training data----------%f%%  %d/%d'%(100*pro,i,len(trsample)))
for i in range(len(tesample)):
    tesample[i][3] = test_visit+tesample[i][2][:6]+'.txt'
    tesample[i][3],_ = loadtimes(tesample[i][3])
    if i%100==0:
        pro = 1.0*i/len(tesample)
        a=time.asctime(time.localtime(time.time()))
        print(a,'---------Reading testing data----------%f%%  %d/%d'%(100*pro,i,len(tesample)))'''

df1=pd.DataFrame(trsample)
df2=pd.DataFrame(tesample)

print('load image time: ',time.clock()-c)



Train_data = df1.sample(n=len(trsample))
Train_xImage = Train_data[0].tolist()
Train_xImage = np.reshape(Train_xImage,(-1,img_size,img_size,n_chanels))
Train_xVisit = np.array(Train_data[3].tolist())
print(Train_xVisit)
Train_xVisit = np.reshape(Train_xVisit,(-1,visit_size))
Train_y = Train_data[1].tolist()
Train_y = np.reshape(Train_y,(-1,n_speces))

Test_data = df2.sample(n=len(tesample))
Test_xImage = Test_data[0].tolist()
Test_xImage = np.reshape(Test_xImage,(-1,img_size,img_size,n_chanels))
Test_Name = Test_data[2]
Test_xVisit = np.array(Test_data[3].tolist())
Test_xVisit = np.reshape(Test_xVisit,(-1,visit_size))
'''
input_data = Input(shape=(img_size,img_size,n_chanels))

Incept1 = Conv2D(64,(1,1),padding='same',activation='relu')(input_data)
Incept1 = Conv2D(64,(1,3),padding='same',activation='relu')(Incept1)
Incept1 = Conv2D(64,(3,1),padding='same',activation='relu')(Incept1)

Incept2 = Conv2D(64,(1,1),padding='same',activation='relu')(input_data)
Incept2 = Conv2D(64,(1,5),padding='same',activation='relu')(Incept2)
Incept2 = Conv2D(64,(5,1),padding='same',activation='relu')(Incept2)

Incept3 = MaxPooling2D((3,3),strides=(1,1),padding='same')(input_data)
Incept3 = Conv2D(64,(1,1),padding='same',activation='relu')(Incept3)

output = concatenate([Incept1,Incept2,Incept3],axis=3)
print(output.shape)
output = AveragePooling2D((10,10))(output)
output = Flatten()(output)
output = Dropout(0.25)(output)
output = Dense(1000,activation='relu')(output)
output = Dense(n_speces,activation='softmax')(output)
adam = Adam(lr=0.001)
reduce_lr = ReduceLROnPlateau(monitor='val_loss',patience=2,
                              factor=0.8,mode='min',min_lr=1e-4)
checkpoint = ModelCheckpoint(os.path.join(MODEL_PATH,'InceptionNet.h5'),
                             monitor='val_loss',mode='min',save_best_only=True)
earlystop = EarlyStopping(monitor='val_loss',patience=5,mode='min',restore_best_weights=True)
model = Model(input = input_data,output = output)
model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])

print('Training-------------')
history = model.fit(  x=Train_xImage,y=Train_y,
                      validation_split=0.1,
                      epochs=20,batch_size=32,
                      shuffle=True,
                      verbose=1,
                      callbacks=[reduce_lr,checkpoint,])
score = model.evaluate(x=Train_xImage, y=Train_y,batch_size=32)
print(score)
model.save('InceptionNet_final.h5')
'''
model = load_model('model\\InceptionNet.h5')
a=time.clock()
pre = model.predict(Test_xImage)
print('time :',time.clock()-a,'\n',pre)
model.summary()

layer_name = 'concatenate_1'
intermediate_layer_model = Model(inputs=model.input,
                                 outputs=model.get_layer(layer_name).output)
intermediate_output = intermediate_layer_model.predict(Test_xImage)
intermediate_output = intermediate_output*255
print(intermediate_output.shape)
show = np.array(intermediate_output[0,:,:,0],dtype=np.uint8)
print(show[50])
cv2.namedWindow('ori',cv2.WINDOW_NORMAL)
cv2.imshow('ori',Test_xImage[0])
cv2.namedWindow('test',cv2.WINDOW_NORMAL)
cv2.imshow('test',show)
cv2.waitKey(0)
